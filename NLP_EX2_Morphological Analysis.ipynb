{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFRe1sCFdaAzWFP+cJQjuY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnPE3sTDM1ri","executionInfo":{"status":"ok","timestamp":1709115329973,"user_tz":-330,"elapsed":1101,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"c226e973-8136-4f2f-be4b-bb6f4de66419"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["--Word--            --Stem--            \n","A                   a                   \n","stemmer             stemmer             \n","for                 for                 \n","English             english             \n","operating           oper                \n","on                  on                  \n","the                 the                 \n","stem                stem                \n","cat                 cat                 \n","should              should              \n","identify            identifi            \n","such                such                \n","strings             string              \n","as                  as                  \n","cats                cat                 \n","catlike             catlik              \n","and                 and                 \n","catty               catti               \n","A                   a                   \n","stemming            stem                \n","algorithm           algorithm           \n","might               might               \n","also                also                \n","reduce              reduc               \n","the                 the                 \n","words               word                \n","fishing             fish                \n","fished              fish                \n","and                 and                 \n","fisher              fisher              \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","fish                fish                \n","The                 the                 \n","stem                stem                \n","need                need                \n","not                 not                 \n","be                  be                  \n","a                   a                   \n","word                word                \n","for                 for                 \n","example             exampl              \n","the                 the                 \n","Porter              porter              \n","algorithm           algorithm           \n","reduces             reduc               \n","argue               argu                \n","argued              argu                \n","argues              argu                \n","arguing             argu                \n","and                 and                 \n","argus               argu                \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","argu                argu                \n"]}],"source":["import string\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","example_sentence = \"A stemmer for English operating on the stem cat should identify such strings as cats, catlike, and catty. A stemming algorithm might also reduce the words fishing, fished, and fisher to the stem fish. The stem need not be a word, for example the Porter algorithm reduces, argue, argued, argues, arguing, and argus to the stem argu.\"\n","# Remove punctuation\n","example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\",\n","string.punctuation))\n","# Create tokens\n","word_tokens = word_tokenize(example_sentence_no_punct)\n","# Perform stemming\n","print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n","for word in word_tokens:\n"," print (\"{0:20}{1:20}\".format(word, ps.stem(word)))"]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\",\n","string.punctuation))\n","# Create tokens\n","word_tokens = word_tokenize(example_sentence_no_punct)\n","# Perform stemming\n","print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n","for word in word_tokens:\n"," print (\"{0:20}{1:20}\".format(word, ps.stem(word)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQantEyQNkQC","executionInfo":{"status":"ok","timestamp":1709115444652,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"6f8f1198-e9da-421e-9808-69fcd9f8406e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--Word--            --Stem--            \n","A                   a                   \n","stemmer             stemmer             \n","for                 for                 \n","English             english             \n","operating           oper                \n","on                  on                  \n","the                 the                 \n","stem                stem                \n","cat                 cat                 \n","should              should              \n","identify            identifi            \n","such                such                \n","strings             string              \n","as                  as                  \n","cats                cat                 \n","catlike             catlik              \n","and                 and                 \n","catty               catti               \n","A                   a                   \n","stemming            stem                \n","algorithm           algorithm           \n","might               might               \n","also                also                \n","reduce              reduc               \n","the                 the                 \n","words               word                \n","fishing             fish                \n","fished              fish                \n","and                 and                 \n","fisher              fisher              \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","fish                fish                \n","The                 the                 \n","stem                stem                \n","need                need                \n","not                 not                 \n","be                  be                  \n","a                   a                   \n","word                word                \n","for                 for                 \n","example             exampl              \n","the                 the                 \n","Porter              porter              \n","algorithm           algorithm           \n","reduces             reduc               \n","argue               argu                \n","argued              argu                \n","argues              argu                \n","arguing             argu                \n","and                 and                 \n","argus               argu                \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","argu                argu                \n"]}]},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","snowball = SnowballStemmer(language='english')\n","# Remove punctuation\n","example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\",\n","string.punctuation))\n","# Create tokens\n","word_tokens = word_tokenize(example_sentence_no_punct)\n","# Perform stemming\n","print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n","for word in word_tokens:\n","  print (\"{0:20}{1:20}\".format(word, snowball.stem(word)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhRf1VHNOB1b","executionInfo":{"status":"ok","timestamp":1709115476660,"user_tz":-330,"elapsed":424,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"98dafa83-f171-4983-d252-875b1210551c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--Word--            --Stem--            \n","A                   a                   \n","stemmer             stemmer             \n","for                 for                 \n","English             english             \n","operating           oper                \n","on                  on                  \n","the                 the                 \n","stem                stem                \n","cat                 cat                 \n","should              should              \n","identify            identifi            \n","such                such                \n","strings             string              \n","as                  as                  \n","cats                cat                 \n","catlike             catlik              \n","and                 and                 \n","catty               catti               \n","A                   a                   \n","stemming            stem                \n","algorithm           algorithm           \n","might               might               \n","also                also                \n","reduce              reduc               \n","the                 the                 \n","words               word                \n","fishing             fish                \n","fished              fish                \n","and                 and                 \n","fisher              fisher              \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","fish                fish                \n","The                 the                 \n","stem                stem                \n","need                need                \n","not                 not                 \n","be                  be                  \n","a                   a                   \n","word                word                \n","for                 for                 \n","example             exampl              \n","the                 the                 \n","Porter              porter              \n","algorithm           algorithm           \n","reduces             reduc               \n","argue               argu                \n","argued              argu                \n","argues              argu                \n","arguing             argu                \n","and                 and                 \n","argus               argus               \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","argu                argu                \n"]}]},{"cell_type":"code","source":["from nltk.stem import LancasterStemmer\n","ls = LancasterStemmer()\n","# Remove punctuation\n","example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\",\n","string.punctuation))\n","# Create tokens\n","word_tokens = word_tokenize(example_sentence_no_punct)\n","# Perform stemming\n","print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n","for word in word_tokens:\n","  print (\"{0:20}{1:20}\".format(word, ls.stem(word)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCp8rNdAOJPy","executionInfo":{"status":"ok","timestamp":1709115506564,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"b4a54005-997b-4e82-a0b8-1ce9bb36cbc6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--Word--            --Stem--            \n","A                   a                   \n","stemmer             stem                \n","for                 for                 \n","English             engl                \n","operating           op                  \n","on                  on                  \n","the                 the                 \n","stem                stem                \n","cat                 cat                 \n","should              should              \n","identify            ident               \n","such                such                \n","strings             strings             \n","as                  as                  \n","cats                cat                 \n","catlike             catlik              \n","and                 and                 \n","catty               catty               \n","A                   a                   \n","stemming            stem                \n","algorithm           algorithm           \n","might               might               \n","also                also                \n","reduce              reduc               \n","the                 the                 \n","words               word                \n","fishing             fish                \n","fished              fish                \n","and                 and                 \n","fisher              fish                \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","fish                fish                \n","The                 the                 \n","stem                stem                \n","need                nee                 \n","not                 not                 \n","be                  be                  \n","a                   a                   \n","word                word                \n","for                 for                 \n","example             exampl              \n","the                 the                 \n","Porter              port                \n","algorithm           algorithm           \n","reduces             reduc               \n","argue               argu                \n","argued              argu                \n","argues              argu                \n","arguing             argu                \n","and                 and                 \n","argus               arg                 \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","argu                argu                \n"]}]},{"cell_type":"code","source":["from nltk.stem import RegexpStemmer\n","regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n","# Remove punctuation\n","example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\",\n","string.punctuation))\n","# Create tokens\n","word_tokens = word_tokenize(example_sentence_no_punct)\n","# Perform stemming\n","print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n","for word in word_tokens:\n","  print (\"{0:20}{1:20}\".format(word, regexp.stem(word)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11zn5uUWOShL","executionInfo":{"status":"ok","timestamp":1709115545815,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"2304379a-c0fb-4348-d41d-6ef5f1f7ec9d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["--Word--            --Stem--            \n","A                   A                   \n","stemmer             stemmer             \n","for                 for                 \n","English             English             \n","operating           operat              \n","on                  on                  \n","the                 the                 \n","stem                stem                \n","cat                 cat                 \n","should              should              \n","identify            identify            \n","such                such                \n","strings             string              \n","as                  as                  \n","cats                cat                 \n","catlike             catlik              \n","and                 and                 \n","catty               catty               \n","A                   A                   \n","stemming            stemm               \n","algorithm           algorithm           \n","might               might               \n","also                also                \n","reduce              reduc               \n","the                 the                 \n","words               word                \n","fishing             fish                \n","fished              fished              \n","and                 and                 \n","fisher              fisher              \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","fish                fish                \n","The                 The                 \n","stem                stem                \n","need                need                \n","not                 not                 \n","be                  be                  \n","a                   a                   \n","word                word                \n","for                 for                 \n","example             exampl              \n","the                 the                 \n","Porter              Porter              \n","algorithm           algorithm           \n","reduces             reduce              \n","argue               argu                \n","argued              argued              \n","argues              argue               \n","arguing             argu                \n","and                 and                 \n","argus               argu                \n","to                  to                  \n","the                 the                 \n","stem                stem                \n","argu                argu                \n"]}]},{"cell_type":"code","source":["#Comparison of various stemmer\n","from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer\n","porter = PorterStemmer()\n","lancaster = LancasterStemmer()\n","snowball = SnowballStemmer(language='english')\n","regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n","word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n","print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(\"Word\",\"PorterStemmer\",\"SnowballStemmer\",\"Lancaster Stemmer\",'Regexp Stemmer'))\n","for word in word_list:\n"," print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),regexp.stem(word)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkpAZTpgOgVC","executionInfo":{"status":"ok","timestamp":1709115611057,"user_tz":-330,"elapsed":427,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"2afa22ff-1e6c-4834-bb3d-b1452b55e04a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Word                PorterStemmer       SnowballStemmer     Lancaster Stemmer             Regexp Stemmer                          \n","friend              friend              friend              friend                        friend                                  \n","friendship          friendship          friendship          friend                        friendship                              \n","friends             friend              friend              friend                        friend                                  \n","friendships         friendship          friendship          friend                        friendship                              \n"]}]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","from nltk.stem import SnowballStemmer\n","def stemming(text):\n","  snowball = SnowballStemmer(language='english')\n","  list=[]\n","  for token in word_tokenize(text):\n","    list.append(snowball.stem(token))\n","\n","  return ' '.join(list)\n","\n","with open('text_file.txt') as f:\n"," text=f.read()\n","print(stemming(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"FFA3C2EQPI66","executionInfo":{"status":"error","timestamp":1709115798395,"user_tz":-330,"elapsed":434,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"7e5d0b00-fcb2-44d3-8d14-72e4d931006d"},"execution_count":13,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'text_file.txt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-c8058257d526>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text_file.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m  \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'text_file.txt'"]}]},{"cell_type":"code","source":["#Wordnet Lemmatizer with NLTK\n","nltk.download('wordnet')\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","# Init the Wordnet Lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","sentence = \"The striped bats are hanging on their feet for best\"\n","# Tokenize: Split the sentence into words\n","word_list = nltk.word_tokenize(sentence)\n","print(word_list)\n","#> ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n","# Lemmatize list of words and join\n","lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n","print(lemmatized_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFDOfjCiPcyk","executionInfo":{"status":"ok","timestamp":1709115847361,"user_tz":-330,"elapsed":2337,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"f69bd697-616c-4d08-bee5-c53158dcd204"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n","The striped bat are hanging on their foot for best\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","nltk.download('averaged_perceptron_tagger')\n","def get_wordnet_pos(word):\n","  \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n","  tag = nltk.pos_tag([word])[0][1][0].upper()\n","  tag_dict = {\"J\": wordnet.ADJ,\n","  \"N\": wordnet.NOUN,\n","  \"V\": wordnet.VERB,\n","  \"R\": wordnet.ADV}\n","  return tag_dict.get(tag, wordnet.NOUN)\n","# 1. Init Lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","# 2. Lemmatize Single Word with the appropriate POS tag\n","word = 'feet'\n","print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))\n","# 3. Lemmatize a Sentence with the appropriate POS tag\n","sentence = \"The striped bats are hanging on their feet for best\"\n","print([lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UoBhF3FhPnu7","executionInfo":{"status":"ok","timestamp":1709116035072,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"632925b4-92b6-4165-94fd-7cdcbf4b0466"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["foot\n","['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"]}]}]}