{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP79nDFqH8nXo7rKfjegIXR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"D1ppNnm65K6U","executionInfo":{"status":"error","timestamp":1710885443607,"user_tz":-330,"elapsed":642,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"0fc2cf8b-7a56-4ea8-d916-5016b2b7d50d","colab":{"base_uri":"https://localhost:8080/","height":332}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'E:/dataset / Cats_vs_Dogs / train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8fa30159c9ef>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m'''Running the training and the testing in the dataset for our model'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-8fa30159c9ef>\u001b[0m in \u001b[0;36mcreate_train_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# tqdm is only used for interactive loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# loading the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m# labeling the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/dataset / Cats_vs_Dogs / train'"]}],"source":["# Python program to create\n","# Image Classifier using CNN\n","\n","# Importing the required libraries\n","import cv2\n","import os\n","import numpy as np\n","from random import shuffle\n","from tqdm import tqdm\n","\n","'''Setting up the env'''\n","\n","TRAIN_DIR = 'E:/dataset / Cats_vs_Dogs / train'\n","TEST_DIR = 'E:/dataset / Cats_vs_Dogs / test1'\n","IMG_SIZE = 50\n","LR = 1e-3\n","\n","\n","'''Setting up the model which will help with tensorflow models'''\n","MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic')\n","\n","'''Labelling the dataset'''\n","def label_img(img):\n","    word_label = img.split('.')[-3]\n","    # DIY One hot encoder\n","    if word_label == 'cat': return [1, 0]\n","    elif word_label == 'dog': return [0, 1]\n","\n","'''Creating the training data'''\n","def create_train_data():\n","    # Creating an empty list where we should store the training data\n","    # after a little preprocessing of the data\n","    training_data = []\n","\n","    # tqdm is only used for interactive loading\n","    # loading the training data\n","    for img in tqdm(os.listdir(TRAIN_DIR)):\n","\n","        # labeling the images\n","        label = label_img(img)\n","\n","        path = os.path.join(TRAIN_DIR, img)\n","\n","        # loading the image from the path and then converting them into\n","        # grayscale for easier covnet prob\n","        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","\n","        # resizing the image for processing them in the covnet\n","        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","\n","        # final step-forming the training data list with numpy array of the images\n","        training_data.append([np.array(img), np.array(label)])\n","\n","    # shuffling of the training data to preserve the random state of our data\n","    shuffle(training_data)\n","\n","    # saving our trained data for further uses if required\n","    np.save('train_data.npy', training_data)\n","    return training_data\n","\n","'''Processing the given test data'''\n","# Almost same as processing the training data but\n","# we dont have to label it.\n","def process_test_data():\n","    testing_data = []\n","    for img in tqdm(os.listdir(TEST_DIR)):\n","        path = os.path.join(TEST_DIR, img)\n","        img_num = img.split('.')[0]\n","        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","        testing_data.append([np.array(img), img_num])\n","\n","    shuffle(testing_data)\n","    np.save('test_data.npy', testing_data)\n","    return testing_data\n","\n","'''Running the training and the testing in the dataset for our model'''\n","train_data = create_train_data()\n","test_data = process_test_data()\n","\n","# train_data = np.load('train_data.npy')\n","# test_data = np.load('test_data.npy')\n","'''Creating the neural network using tensorflow'''\n","# Importing the required libraries\n","import tflearn\n","from tflearn.layers.conv import conv_2d, max_pool_2d\n","from tflearn.layers.core import input_data, dropout, fully_connected\n","from tflearn.layers.estimator import regression\n","\n","import tensorflow as tf\n","tf.compat.v1.reset_default_graph()\n","convnet = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input')\n","\n","convnet = conv_2d(convnet, 32, 5, activation ='relu')\n","convnet = max_pool_2d(convnet, 5)\n","\n","convnet = conv_2d(convnet, 64, 5, activation ='relu')\n","convnet = max_pool_2d(convnet, 5)\n","\n","convnet = conv_2d(convnet, 128, 5, activation ='relu')\n","convnet = max_pool_2d(convnet, 5)\n","\n","convnet = conv_2d(convnet, 64, 5, activation ='relu')\n","convnet = max_pool_2d(convnet, 5)\n","\n","convnet = conv_2d(convnet, 32, 5, activation ='relu')\n","convnet = max_pool_2d(convnet, 5)\n","\n","convnet = fully_connected(convnet, 1024, activation ='relu')\n","convnet = dropout(convnet, 0.8)\n","\n","convnet = fully_connected(convnet, 2, activation ='softmax')\n","convnet = regression(convnet, optimizer ='adam', learning_rate = LR,\n","    loss ='categorical_crossentropy', name ='targets')\n","\n","model = tflearn.DNN(convnet, tensorboard_dir ='log')\n","\n","# Splitting the testing data and training data\n","train = train_data[:-500]\n","test = train_data[-500:]\n","\n","'''Setting up the features and labels'''\n","# X-Features & Y-Labels\n","\n","X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n","Y = np.array([i[1] for i in train])\n","test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n","test_y = np.array([i[1] for i in test])\n","\n","'''Fitting the data into our model'''\n","# epoch = 5 taken\n","model.fit({'input': X}, {'targets': Y}, n_epoch = 5,\n","    validation_set =({'input': test_x}, {'targets': test_y}),\n","    snapshot_step = 500, show_metric = True, run_id = MODEL_NAME)\n","model.save(MODEL_NAME)\n","\n","'''Testing the data'''\n","import matplotlib.pyplot as plt\n","# if you need to create the data:\n","# test_data = process_test_data()\n","# if you already have some saved:\n","test_data = np.load('test_data.npy')\n","\n","fig = plt.figure()\n","\n","for num, data in enumerate(test_data[:20]):\n","    # cat: [1, 0]\n","    # dog: [0, 1]\n","\n","    img_num = data[1]\n","    img_data = data[0]\n","\n","    y = fig.add_subplot(4, 5, num + 1)\n","    orig = img_data\n","    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n","\n","    # model_out = model.predict([data])[0]\n","    model_out = model.predict([data])[0]\n","\n","    if np.argmax(model_out) == 1: str_label ='Dog'\n","    else: str_label ='Cat'\n","\n","    y.imshow(orig, cmap ='gray')\n","    plt.title(str_label)\n","    y.axes.get_xaxis().set_visible(False)\n","    y.axes.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","# Load the CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","# Preprocess the data\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n","# Build the CNN model\n","model = tf.keras.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32,\n","3)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","# Compile the model\n","model.compile(optimizer='adam',\n","loss='categorical_crossentropy',\n","metrics=['accuracy'])\n","# Train the model\n","model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n","# Evaluate the model\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(f'Test loss: {loss:.4f}')\n","print(f'Test accuracy: {accuracy:.4f}')"],"metadata":{"id":"LWo_kJtm7d0m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711094171547,"user_tz":-330,"elapsed":615134,"user":{"displayName":"Arshitha S snsce-ad","userId":"17227574827762348735"}},"outputId":"7b704241-2876-4204-cb81-cd20c0961fbb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 7s 0us/step\n","Epoch 1/10\n","1563/1563 [==============================] - 211s 134ms/step - loss: 1.5996 - accuracy: 0.4205 - val_loss: 1.1872 - val_accuracy: 0.5917\n","Epoch 2/10\n","1563/1563 [==============================] - 209s 133ms/step - loss: 1.2439 - accuracy: 0.5579 - val_loss: 1.0455 - val_accuracy: 0.6389\n","Epoch 3/10\n","1563/1563 [==============================] - 206s 132ms/step - loss: 1.1259 - accuracy: 0.6043 - val_loss: 0.9723 - val_accuracy: 0.6596\n","Epoch 4/10\n","1563/1563 [==============================] - 203s 130ms/step - loss: 1.0417 - accuracy: 0.6297 - val_loss: 0.9718 - val_accuracy: 0.6558\n","Epoch 5/10\n","1563/1563 [==============================] - 208s 133ms/step - loss: 0.9811 - accuracy: 0.6528 - val_loss: 0.9197 - val_accuracy: 0.6795\n","Epoch 6/10\n","1563/1563 [==============================] - 205s 131ms/step - loss: 0.9294 - accuracy: 0.6699 - val_loss: 0.9077 - val_accuracy: 0.6787\n","Epoch 7/10\n","1563/1563 [==============================] - 203s 130ms/step - loss: 0.8890 - accuracy: 0.6856 - val_loss: 0.8887 - val_accuracy: 0.6939\n","Epoch 8/10\n","1563/1563 [==============================] - 208s 133ms/step - loss: 0.8385 - accuracy: 0.6995 - val_loss: 0.8879 - val_accuracy: 0.6889\n","Epoch 9/10\n","1563/1563 [==============================] - 210s 134ms/step - loss: 0.8029 - accuracy: 0.7128 - val_loss: 0.8767 - val_accuracy: 0.7036\n","Epoch 10/10\n","1563/1563 [==============================] - 207s 133ms/step - loss: 0.7679 - accuracy: 0.7239 - val_loss: 0.8896 - val_accuracy: 0.6959\n","313/313 [==============================] - 11s 35ms/step - loss: 0.8896 - accuracy: 0.6959\n","Test loss: 0.8896\n","Test accuracy: 0.6959\n"]}]}]}